{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the model is an image that only contains handwritten text. The outputs are bounding boxes that correspond to each line of the text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SSD architecture essentially takes image features and repeatedly downsamples the features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSD: Single Shot MultiBox Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import importlib\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "#Importing all the required libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "random.seed(123)\n",
    "import glob\n",
    "import cv2\n",
    "from os.path import splitext,basename\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "pwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "numbers = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numbers, y_numbers = numbers[\"data\"], numbers[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numbers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "row, column = 4, 4\n",
    "\n",
    "for i in range(16): \n",
    "    plt.subplot(column, row, i+1)\n",
    "    some_digit = X_numbers[69000+i]\n",
    "    some_digit_image = some_digit.reshape(28,28)\n",
    "    plt.imshow(some_digit_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.sort(y_numbers))\n",
    "plt.title(\"Histogram of Single Digits\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd = os.getcwd()\n",
    "letters_uppercase = pd.read_csv(os.path.basename(pwd + '/az.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_uppercase.rename(columns={'0':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change label to alphabet\n",
    "alphabets_mapper = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P'\n",
    "                    ,16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X',24:'Y',25:'Z'} \n",
    "letters_uppercase['label'] = letters_uppercase['label'].map(alphabets_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_letters_uppercase = letters_uppercase.drop('label',axis = 1)\n",
    "y_letters_uppercase = letters_uppercase['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_letters_uppercase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "sns.histplot(y_letters_uppercase)\n",
    "plt.title(\"Histogram of Single Uppercase Letters\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = pwd+r\"\\letters-small\"\n",
    "categories = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(datadir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        #check image\n",
    "        plt.imshow(img_array, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_sq = img_size*img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_lowercase = []\n",
    "\n",
    "def create_dataset():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                letters_lowercase.append([new_array, category])\n",
    "            except Exception as e:\n",
    "                break\n",
    "create_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_letters_lowercase = []\n",
    "y_letters_lowercase = []\n",
    "\n",
    "for features, label in letters_lowercase:\n",
    "    X_letters_lowercase.append(features)\n",
    "    y_letters_lowercase.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_letters_lowercase = np.reshape(X_letters_lowercase,(len(X_letters_lowercase),img_size_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_letters_lowercase= [str(i) for i in y_letters_lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5))\n",
    "sns.histplot(y_letters_lowercase)\n",
    "plt.title(\"Histogram of Single Lowercase Letters\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X_letters_uppercase, X_letters_lowercase, X_numbers), axis=0)\n",
    "y = np.concatenate((y_letters_uppercase, y_letters_lowercase, y_numbers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reshape = y.reshape(-1, 1) #Encoder requires 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the label column\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "y_ord = ordinal_encoder.fit_transform(y_reshape)\n",
    "y_ord[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to integer\n",
    "\n",
    "y_int = y_ord.astype(int)\n",
    "y_int.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_std, y_int, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm = SMOTE(random_state = 2) \n",
    "#train_x_res, train_y_res = sm.fit_sample(train_x, train_y.ravel()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 10,000 samples for validation\n",
    "x_val = train_x[-10000:]\n",
    "y_val = train_y[-10000:]\n",
    "train_x = train_x[:-10000]\n",
    "train_y = train_y[:-10000]\n",
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "np.random.seed(42) # fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(50, input_dim=784, activation='relu'))\n",
    "model1.add(Dense(25, activation='relu'))\n",
    "model1.add(Dense(10, activation='relu'))\n",
    "model1.add(Dense(62, activation='softmax')) #we have 36 categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "sgd = keras.optimizers.SGD(lr=0.05)\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model1.fit(train_x, train_y, epochs=60, batch_size=100 ,validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model1.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model1.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "for i, correct in enumerate(test_y[:12]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(test_x[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted: {}, Truth: {}\".format(prediction[correct],\n",
    "                                        test_y[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(100, input_dim=784, activation='relu'))\n",
    "model2.add(Dense(50, activation='relu'))\n",
    "model2.add(Dense(25, activation='relu'))\n",
    "\n",
    "model2.add(Dense(36, activation='sigmoid')) #we have 36 categories\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "sgd= keras.optimizers.SGD(lr=0.05)\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "model2_history= model2.fit(train_x, train_y, epochs=50, batch_size=100,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model2.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]\n",
    "\n",
    "model2.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "          epochs=100, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model2.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph\n",
    "plt.clf()\n",
    "accuracy = model2_history.history['accuracy']\n",
    "val_accuracy = model2_history.history['val_accuracy']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, 'g', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'y', label='Validation Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "loss = model2_history.history['loss']\n",
    "val_loss = model2_history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path,resize=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line/word segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def line_array(array):\n",
    "    list_x_upper = []\n",
    "    list_x_lower = []\n",
    "    for y in range(5, len(array)-5):\n",
    "        s_a, s_p = strtline(y, array)\n",
    "        e_a, e_p = endline(y, array)\n",
    "        print(str(s_a) + ',' + str(s_p) + ',' + str(e_a) + ',' + str(e_p) + ',' + str(y))\n",
    "        if s_a>=7 and s_p>=5:\n",
    "            list_x_upper.append(y)\n",
    "        # bin_img[y][:] = 255\n",
    "        if e_a>=5 and e_p>=7:\n",
    "            list_x_lower.append(y)\n",
    "            # bin_img[y][:] = 255\n",
    "    return list_x_upper, list_x_lower\n",
    "\n",
    "def strtline(y, array):\n",
    "    count_ahead = 0\n",
    "    count_prev = 0\n",
    "    for i in array[y:y+10]:\n",
    "        if i > 3:\n",
    "            count_ahead+= 1  \n",
    "    for i in array[y-10:y]:\n",
    "        if i == 0:\n",
    "            count_prev += 1  \n",
    "    return count_ahead, count_prev\n",
    "\n",
    "def endline(y, array):\n",
    "    count_ahead = 0\n",
    "    count_prev = 0\n",
    "    for i in array[y:y+10]:\n",
    "        if i==0:\n",
    "            count_ahead+= 1  \n",
    "    for i in array[y-10:y]:\n",
    "        if i >3:\n",
    "            count_prev += 1  \n",
    "    return count_ahead, count_prev\n",
    "\n",
    "def endline_word(y, array, a):\n",
    "    count_ahead = 0\n",
    "    count_prev = 0\n",
    "    for i in array[y:y+2*a]:\n",
    "        if i < 2:\n",
    "            count_ahead+= 1  \n",
    "    for i in array[y-a:y]:\n",
    "        if i > 2:\n",
    "            count_prev += 1  \n",
    "    return count_prev ,count_ahead\n",
    "\n",
    "def end_line_array(array, a):\n",
    "    list_endlines = []\n",
    "    for y in range(len(array)):\n",
    "        e_p, e_a = endline_word(y, array, a)\n",
    "        #print(e_p, e_a)\n",
    "        if e_a >= int(0.8*a) and e_p >= int(0.7*a):\n",
    "            list_endlines.append(y)\n",
    "    return list_endlines\n",
    "\n",
    "def refine_endword(array):\n",
    "    refine_list = []\n",
    "    for y in range(len(array)-1):\n",
    "        if array[y]+1 < array[y+1]:\n",
    "            refine_list.append(array[y])\n",
    "    refine_list.append(array[-1])\n",
    "    return refine_list\n",
    "\n",
    "\n",
    "def refine_array(array_upper, array_lower):\n",
    "    upperlines = []\n",
    "    lowerlines = []\n",
    "    for y in range(len(array_upper)-1):\n",
    "        if array_upper[y] + 5 < array_upper[y+1]:\n",
    "            upperlines.append(array_upper[y]-10)\n",
    "    for y in range(len(array_lower)-1):\n",
    "        if array_lower[y] + 5 < array_lower[y+1]:\n",
    "            lowerlines.append(array_lower[y]+10)\n",
    "\n",
    "    upperlines.append(array_upper[-1]-10)\n",
    "    lowerlines.append(array_lower[-1]+10)\n",
    "    \n",
    "    return upperlines, lowerlines\n",
    "\n",
    "def letter_width(contours):\n",
    "    letter_width_sum = 0\n",
    "    count = 0\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 20:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            letter_width_sum += w\n",
    "            count += 1\n",
    "\n",
    "    return letter_width_sum/count\n",
    "\n",
    "\n",
    "def end_wrd_dtct(final_local, i, bin_img, mean_lttr_width):\n",
    "    count_y = np.zeros(shape = width)\n",
    "    for x in range(width):\n",
    "        for y in range(final_local[i],final_local[i+1]):\n",
    "            if bin_img[y][x] == 255:\n",
    "                count_y[x] += 1\n",
    "    #end_lines = end_line_array(count_y, int(mean_lttr_width))\n",
    "    #endlines = refine_endword(end_lines)\n",
    "    #print(i)\n",
    "    '''for x in range(len(count_y)):\n",
    "        if max(count_y[0:x+1]) >= 3 and max(count_y[x:]) >= 3 and (20-np.count_nonzero(count_y[x-10:x+10])) > 6:\n",
    "            print(x)'''\n",
    "\n",
    "#     chalu_img, \n",
    "    contours, hierarchy = cv2.findContours(lines_img[i], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    letter_width_sum = 0\n",
    "    count = 0\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 20:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            letter_width_sum += w\n",
    "            count += 1\n",
    "    if count != 0 :\n",
    "        mean_width = letter_width_sum / count\n",
    "    else:\n",
    "        mean_width = 0\n",
    "    #print(mean_width)\n",
    "    spaces = []\n",
    "    line_end = []\n",
    "    for x in range(len(count_y)):\n",
    "        number = int(0.5*int(mean_width)) - np.count_nonzero(count_y[x-int(0.25*int(mean_width)):x+int(0.25*int(mean_width))])\n",
    "        if max(count_y[0:x + 1]) >= 3 and number >= 0.4*int(mean_width):\n",
    "            spaces.append(x)\n",
    "        if max(count_y[x:]) <= 2:\n",
    "            line_end.append(x)\n",
    "    true_line_end = min(line_end) + 10\n",
    "    #spaces = refine_endword(spaces)\n",
    "    #print(spaces)\n",
    "    #print(true_line_end)\n",
    "    reti = []\n",
    "    final_spaces = []\n",
    "    for j in range(len(spaces)):\n",
    "        if spaces[j] < true_line_end:\n",
    "            if spaces[j] == spaces[j-1] + 1:\n",
    "                reti.append(spaces[j-1])\n",
    "            elif spaces[j] != spaces[j-1] + 1 and spaces[j-1] == spaces[j-2] +1:\n",
    "                reti.append(spaces[j-1])\n",
    "                retiavg = int(sum(reti)/len(reti))\n",
    "                final_spaces.append(retiavg)\n",
    "                reti = []\n",
    "            elif spaces[j] != spaces[j-1] + 1 and spaces[j-1] != spaces[j-2] +1 and spaces[j] != spaces[j+1] -1:\n",
    "                final_spaces.append(spaces[j])\n",
    "        elif spaces[j] == true_line_end:\n",
    "            final_spaces.append(true_line_end)\n",
    "    #print(final_spaces)\n",
    "    for x in final_spaces:\n",
    "        final_thr[final_local[i]:final_local[i+1], x] = 255\n",
    "    return final_spaces\n",
    "\n",
    "\n",
    "def letter_seg(lines_img, x_lines, i):\n",
    "    copy_img = lines_img[i].copy()\n",
    "    x_linescopy = x_lines[i].copy()\n",
    "    \n",
    "    letter_img = []\n",
    "    letter_k = []\n",
    "    \n",
    "#     chalu_img, \n",
    "    contours, hierarchy = cv2.findContours(copy_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)   \n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 5:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            # letter_img.append(lines_img[i][y:y+h, x:x+w])\n",
    "            letter_k.append((x,y,w,h))\n",
    "\n",
    "    letter_width_sum = 0\n",
    "    count = 0\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 20:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            letter_width_sum += h\n",
    "            count += 1\n",
    "\n",
    "    #mean_height = letter_width_sum/count\n",
    "\n",
    "    letter = sorted(letter_k, key=lambda student: student[0])\n",
    "\n",
    "    for e in range(len(letter)):\n",
    "        if e < len(letter)-1:\n",
    "            if abs(letter[e][0] - letter[e+1][0]) <= 2:\n",
    "                x,y,w,h = letter[e]\n",
    "                x2,y2,w2,h2 = letter[e+1]\n",
    "                if h >= h2:\n",
    "                    letter[e] = (x,y2,w,h+h2)\n",
    "                    letter.pop(e+1)\n",
    "                elif h < h2:\n",
    "                    letter[e+1] = (x2,y,w2,h+h2)\n",
    "                    letter.pop(e)\n",
    "\n",
    "    for e in range(len(letter)):\n",
    "        letter_img_tmp = lines_img[i][letter[e][1]-0:letter[e][1]+letter[e][3]+0,letter[e][0]-0:letter[e][0]+letter[e][2]+0]\n",
    "        letter_img_tmp = cv2.resize(letter_img_tmp, dsize=(28, 28), interpolation=cv2.INTER_AREA)\n",
    "        width = letter_img_tmp.shape[1]\n",
    "        height = letter_img_tmp.shape[0]\n",
    "        count_y = np.zeros(shape=(width))\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                if letter_img_tmp[y][x] == 255:\n",
    "                    count_y[x] = count_y[x] +1\n",
    "        print(count_y)\n",
    "        max_list = []\n",
    "        for z in range(len(count_y)):\n",
    "            if z>=5 and z<= len(count_y)-6:\n",
    "                if max(count_y[z-5:z+6]) == count_y[z] and count_y[z] >= 2:\n",
    "                    max_list.append(z)\n",
    "            elif z<5:\n",
    "                if max(count_y[0:z+6]) == count_y[z] and count_y[z] >= 2:\n",
    "                    max_list.append(z)\n",
    "            elif z > len(count_y)-6:\n",
    "                if max(count_y[z-5:len(count_y)-1]) == count_y[z] and count_y[z] >= 2:\n",
    "                    max_list.append(z)\n",
    "        print(max_list)\n",
    "        rem_list = []\n",
    "        final_max_list = []\n",
    "        for z in range(len(max_list)):\n",
    "            if z > 0:\n",
    "                if max_list[z]-max_list[z-1] <= 3:\n",
    "                    rem_list.append(z-1)\n",
    "        for z in range(len(max_list)):\n",
    "            if z not in rem_list:\n",
    "                final_max_list.append(max_list[z])\n",
    "        print(final_max_list)\n",
    "        if len(final_max_list) <= 1:\n",
    "            print(False)\n",
    "        else:\n",
    "            max_len = len(final_max_list) - 1\n",
    "            for j in range(max_len):\n",
    "                list = count_y[final_max_list[j]:final_max_list[j+1]]\n",
    "                min_list = sorted(list)[:3]\n",
    "                avg = sum(min_list)/len(min_list)\n",
    "                print(avg)\n",
    "\n",
    "\n",
    "\n",
    "    x_linescopy.pop(0)\n",
    "    word = 1\n",
    "    letter_index = 0\n",
    "    for e in range(len(letter)):\n",
    "        #print(str(letter[e][0]) + ',' + str(letter[e][1]) + ',' + str(letter[e][2]) + ',' + str(letter[e][3]) + ',' + str(e))\n",
    "        if(letter[e][0]<x_linescopy[0]):\n",
    "            letter_index += 1\n",
    "            letter_img_tmp = lines_img[i][letter[e][1]-0:letter[e][1]+letter[e][3]+5,letter[e][0]-2:letter[e][0]+letter[e][2]+2]\n",
    "            letter_img = cv2.resize(letter_img_tmp, dsize =(28, 28), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imwrite('./segmented_img/img1/'+str(i+1)+'_'+str(word)+'_'+str(letter_index)+'.jpg', 255-letter_img)\n",
    "        else:\n",
    "            x_linescopy.pop(0)\n",
    "            word += 1\n",
    "            letter_index = 1\n",
    "            letter_img_tmp = lines_img[i][letter[e][1]-0:letter[e][1]+letter[e][3]+5,letter[e][0]-2:letter[e][0]+letter[e][2]+2]\n",
    "            letter_img = cv2.resize(letter_img_tmp, dsize =(28, 28), interpolation = cv2.INTER_AREA)\n",
    "            cv2.imwrite('./segmented_img/img1/'+str(i+1)+'_'+str(word)+'_'+str(letter_index)+'.jpg', 255-letter_img)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_img= cv2.imread(pwd+r'/Hi.jpeg', 1)\n",
    "copy = src_img.copy()\n",
    "height = src_img.shape[0]\n",
    "width = src_img.shape[1]\n",
    "#  Resizing Image\n",
    "src_img = cv2.resize(copy, dsize =(1320, int(1320*height/width)), interpolation = cv2.INTER_AREA)\n",
    "height = src_img.shape[0]\n",
    "width = src_img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#---------Image Info:--------#\")\n",
    "print(\"\\tHeight =\",height,\"\\n\\tWidth =\",width)\n",
    "print(\"#----------------------------#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Applying Adaptive Threshold with kernel :- 21 X 21\n",
    "bin_img = cv2.adaptiveThreshold(grey_img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,21,20)\n",
    "coords = np.column_stack(np.where(bin_img > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "else:\n",
    "    angle = -angle\n",
    "h = bin_img.shape[0]\n",
    "w = bin_img.shape[1]\n",
    "center = (w//2,h//2)\n",
    "angle = 0\n",
    "M = cv2.getRotationMatrix2D(center,angle,1.0)\n",
    "bin_img = cv2.warpAffine(bin_img,M,(w,h),\n",
    "                         flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "bin_img1 = bin_img.copy()\n",
    "bin_img2 = bin_img.copy()\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "kernel1 = np.array([[1,0,1],[0,1,0],[1,0,1]], dtype = np.uint8)\n",
    "final_thr = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel)\n",
    "contr_retrival = final_thr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning Character Segmentation\n",
    "count_x = np.zeros(shape= (height))\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if bin_img[y][x] == 255 :\n",
    "            count_x[y] = count_x[y]+1\n",
    "\n",
    "local_minima = []\n",
    "for y in range(len(count_x)):\n",
    "    if y >= 10 and y <= len(count_x)-11:\n",
    "        arr1 = count_x[y-10:y+10]\n",
    "    elif y < 10:\n",
    "        arr1 = count_x[0:y+10]\n",
    "    else:\n",
    "        arr1 = count_x[y-10:len(count_x)-1]\n",
    "    if min(arr1) == count_x[y]:\n",
    "        local_minima.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_local = []\n",
    "init = []\n",
    "end = []\n",
    "for z in range(len(local_minima)):\n",
    "    if z != 0 and z!= len(local_minima)-1:\n",
    "        if local_minima[z] != (local_minima[z-1] +1) and local_minima[z] != (local_minima[z+1] -1):\n",
    "            final_local.append(local_minima[z])\n",
    "        elif local_minima[z] != (local_minima[z-1] + 1) and local_minima[z] == (local_minima[z+1] -1):\n",
    "            init.append(local_minima[z])\n",
    "        elif local_minima[z] == (local_minima[z-1] + 1) and local_minima[z] != (local_minima[z+1] -1):\n",
    "            end.append(local_minima[z])\n",
    "    elif z == 0:\n",
    "        if local_minima[z] != (local_minima[z+1]-1):\n",
    "            final_local.append(local_minima[z])\n",
    "        elif local_minima[z] == (local_minima[z+1]-1):\n",
    "            init.append(local_minima[z])\n",
    "    elif z == len(local_minima)-1:\n",
    "        if local_minima[z] != (local_minima[z-1]+1):\n",
    "            final_local.append(local_minima[z])\n",
    "        elif local_minima[z] == (local_minima[z-1]+1):\n",
    "            end.append(local_minima[z])\n",
    "for j in range(len(init)):\n",
    "    mid = (init[j] + end[j])/2\n",
    "    if (mid % 1) != 0:\n",
    "        mid = mid+0.5\n",
    "    final_local.append(int(mid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_local = sorted(final_local)\n",
    "no_of_lines = len(final_local) - 1\n",
    "print(\"\\nGiven Text has   # \",no_of_lines, \" #   no. of Characters\")\n",
    "lines_img = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(no_of_lines):\n",
    "    lines_img.append(bin_img2[final_local[i]:final_local[i+1], :])\n",
    "\n",
    "contours, hierarchy = cv2.findContours(contr_retrival,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "final_contr = np.zeros((final_thr.shape[0],final_thr.shape[1],3), dtype = np.uint8)\n",
    "cv2.drawContours(src_img, contours, -1, (0,255,0), 1)\n",
    "mean_lttr_width = letter_width(contours)\n",
    "plt.imshow(final_thr)\n",
    "print(\"\\nAverage Width of Each Letter:- \", mean_lttr_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lines = []\n",
    "\n",
    "for i in range(len(lines_img)):\n",
    "    x_lines.append(end_wrd_dtct(final_local, i, bin_img, mean_lttr_width))\n",
    "\n",
    "for i in range(len(x_lines)):\n",
    "    x_lines[i].append(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------Letter Segmentation-------------#\n",
    "def sort_contours(cnts,reverse = False):\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "    return cnts\n",
    "\n",
    "\n",
    "chr_img = bin_img1.copy()\n",
    "contours, hierarchy = cv2.findContours(chr_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# digit_w, digit_h = 30, 60\n",
    "digit_w, digit_h = 28, 28\n",
    "crop_characters = []\n",
    "\n",
    "for cnt in sort_contours(contours):\n",
    "    \n",
    "    if cv2.contourArea(cnt) > 20: \n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(src_img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "        curr_num = final_thr[y:y+h,x:x+w]\n",
    "        curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
    "        _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        crop_characters.append(curr_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\n",
    "plot_image = [ final_thr, bin_img, src_img]\n",
    "plot_name = [\"\",\"Binary image\",\"Image segmentation\"]\n",
    "\n",
    "fig = plt.figure(figsize=(30,15)) \n",
    "grid = gridspec.GridSpec(ncols=2,nrows=2,figure = fig)\n",
    "for i in range(len(plot_image)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.title(plot_name[i])\n",
    "    if i ==0:\n",
    "        plt.imshow(plot_image[i])\n",
    "    else:\n",
    "        plt.imshow(plot_image[i],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\n",
    "# plt.imshow(crop_characters[0],cmap=\"gray\")\n",
    "\n",
    "for i in range(len(crop_characters)):\n",
    "\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.imshow(crop_characters[i],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "crop_characters[2].shape\n",
    "plt.imshow(crop_characters[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,3))\n",
    "cols = len(crop_characters)\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\n",
    "\n",
    "final_string = ''\n",
    "for i,character in enumerate(crop_characters):\n",
    "    fig.add_subplot(grid[i])\n",
    "    crop_characters[i]=crop_characters[i]/255\n",
    "    crop_characters[i] = np.reshape(crop_characters[i],[1,784])\n",
    "    \n",
    "    title = model1.predict_classes(crop_characters[i])\n",
    "    plt.title(\"{}\".format(title))\n",
    "    plt.axis(False)\n",
    "    plt.imshow(character,cmap='gray')\n",
    "\n",
    "print(final_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "json_file = open(pwd+r'\\MobileNets_character_recognition.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(pwd+r'\\License_character_recognition_weight.h5')\n",
    "model.summary()\n",
    "labels = LabelEncoder()\n",
    "labels.classes_ = np.load(pwd+r'\\license_character_classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, 'g', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'y', label='Validation Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_utils import detect_lp\n",
    "def preprocess_image(image_path,resize=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img\n",
    "\n",
    "def get_plate(image_path, Dmax=608, Dmin=256):\n",
    "    vehicle = preprocess_image(image_path)\n",
    "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
    "    side = int(ratio * Dmin)\n",
    "    bound_dim = min(side, Dmax)\n",
    "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
    "    return LpImg, cor\n",
    "\n",
    "def load_model(path):\n",
    "    try:\n",
    "        path = splitext(path)[0]\n",
    "        with open('%s.json' % path, 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        model = model_from_json(model_json, custom_objects={})\n",
    "        model.load_weights('%s.h5' % path)\n",
    "        print(\"Loading model successfully...\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "wpod_net_path = \"wpod-net.json\"\n",
    "wpod_net = load_model(wpod_net_path)\n",
    "\n",
    "test_image = pwd+r'\\Cars252.png'\n",
    "print(test_image)\n",
    "LpImg,cor = get_plate(test_image)\n",
    "print(\"Detect %i plate(s) in\"%len(LpImg),splitext(basename(test_image))[0])\n",
    "print(\"Coordinate of plate(s) in image: \\n\", cor)\n",
    "\n",
    "# Visualize our result\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(False)\n",
    "plt.imshow(preprocess_image(test_image))\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(False)\n",
    "plt.imshow(LpImg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #check if there is at least one license image\n",
    "# Scales, calculates absolute values, and converts the result to 8-bit.\n",
    "plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n",
    "\n",
    "# convert to grayscale and blur the image\n",
    "gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(7,7),0)\n",
    "\n",
    "# Applied inversed thresh_binary \n",
    "binary = cv2.threshold(blur, 180, 255,\n",
    "                     cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n",
    "\n",
    "    \n",
    "# visualize results    \n",
    "fig = plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\"font.size\":18})\n",
    "grid = gridspec.GridSpec(ncols=2,nrows=3,figure = fig)\n",
    "plot_image = [plate_image, gray, blur, binary,thre_mor]\n",
    "plot_name = [\"Plate image\",\"Gray\",\"Blur\",\"Binary\",\"Dilation\"]\n",
    "\n",
    "for i in range(len(plot_image)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.title(plot_name[i])\n",
    "    if i ==0:\n",
    "        plt.imshow(plot_image[i])\n",
    "    else:\n",
    "        plt.imshow(plot_image[i],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts,reverse = False):\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "    return cnts\n",
    "\n",
    "cont, _  = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# creat a copy version \"test_roi\" of plat_image to draw bounding box\n",
    "test_roi = plate_image.copy()\n",
    "\n",
    "# Initialize a list which will be used to append charater image\n",
    "crop_characters = []\n",
    "\n",
    "# define standard width and height of character\n",
    "digit_w, digit_h = 30, 60\n",
    "\n",
    "for c in sort_contours(cont):\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    ratio = h/w\n",
    "    if 1<=ratio<=3.5: # Only select contour with defined ratio\n",
    "        if h/plate_image.shape[0]>=0.5: # Select contour which has the height larger than 50% of the plate\n",
    "            # Draw bounding box arroung digit number\n",
    "            cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255,0), 2)\n",
    "\n",
    "            # Sperate number and gibe prediction\n",
    "            curr_num = thre_mor[y:y+h,x:x+w]\n",
    "            curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
    "            _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            crop_characters.append(curr_num)\n",
    "\n",
    "print(\"Detect {} letters...\".format(len(crop_characters)))\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.axis(False)\n",
    "plt.imshow(test_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\n",
    "\n",
    "for i in range(len(crop_characters)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.imshow(crop_characters[i],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_model(image,model,labels):\n",
    "    image = cv2.resize(image,(80,80))\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,3))\n",
    "cols = len(crop_characters)\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\n",
    "\n",
    "final_string = ''\n",
    "for i,character in enumerate(crop_characters):\n",
    "    fig.add_subplot(grid[i])\n",
    "    title = np.array2string(predict_from_model(character,model,labels))\n",
    "    plt.title('{}'.format(title.strip(\"'[]\"),fontsize=20))\n",
    "    final_string+=title.strip(\"'[]\")\n",
    "    plt.axis(False)\n",
    "    plt.imshow(character,cmap='gray')\n",
    "\n",
    "print(final_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License plate Recogniton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "json_file = open(pwd+r'\\MobileNets_character_recognition.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(pwd+r'\\License_character_recognition_weight.h5')\n",
    "model.summary()\n",
    "labels = LabelEncoder()\n",
    "labels.classes_ = np.load(pwd+r'\\license_character_classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from local_utils import detect_lp\n",
    "def preprocess_image(image_path,resize=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img\n",
    "\n",
    "def get_plate(image_path, Dmax=608, Dmin=256):\n",
    "    vehicle = preprocess_image(image_path)\n",
    "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
    "    side = int(ratio * Dmin)\n",
    "    bound_dim = min(side, Dmax)\n",
    "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
    "    return LpImg, cor\n",
    "\n",
    "def load_model(path):\n",
    "    try:\n",
    "        path = splitext(path)[0]\n",
    "        with open('%s.json' % path, 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        model = model_from_json(model_json, custom_objects={})\n",
    "        model.load_weights('%s.h5' % path)\n",
    "        print(\"Loading model successfully...\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "wpod_net_path = \"wpod-net.json\"\n",
    "wpod_net = load_model(wpod_net_path)\n",
    "\n",
    "test_image = pwd+r'\\Cars252.png'\n",
    "print(test_image)\n",
    "LpImg,cor = get_plate(test_image)\n",
    "print(\"Detect %i plate(s) in\"%len(LpImg),splitext(basename(test_image))[0])\n",
    "print(\"Coordinate of plate(s) in image: \\n\", cor)\n",
    "\n",
    "# Visualize our result\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(False)\n",
    "plt.imshow(preprocess_image(test_image))\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(False)\n",
    "plt.imshow(LpImg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #check if there is at least one license image\n",
    "# Scales, calculates absolute values, and converts the result to 8-bit.\n",
    "plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n",
    "\n",
    "# convert to grayscale and blur the image\n",
    "gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(7,7),0)\n",
    "\n",
    "# Applied inversed thresh_binary \n",
    "binary = cv2.threshold(blur, 180, 255,\n",
    "                     cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n",
    "\n",
    "    \n",
    "# visualize results    \n",
    "fig = plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\"font.size\":18})\n",
    "grid = gridspec.GridSpec(ncols=2,nrows=3,figure = fig)\n",
    "plot_image = [plate_image, gray, blur, binary,thre_mor]\n",
    "plot_name = [\"Plate image\",\"Gray\",\"Blur\",\"Binary\",\"Dilation\"]\n",
    "\n",
    "for i in range(len(plot_image)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.title(plot_name[i])\n",
    "    if i ==0:\n",
    "        plt.imshow(plot_image[i])\n",
    "    else:\n",
    "        plt.imshow(plot_image[i],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts,reverse = False):\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "    return cnts\n",
    "\n",
    "cont, _  = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# creat a copy version \"test_roi\" of plat_image to draw bounding box\n",
    "test_roi = plate_image.copy()\n",
    "\n",
    "# Initialize a list which will be used to append charater image\n",
    "crop_characters = []\n",
    "\n",
    "# define standard width and height of character\n",
    "digit_w, digit_h = 30, 60\n",
    "\n",
    "for c in sort_contours(cont):\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    ratio = h/w\n",
    "    if 1<=ratio<=3.5: # Only select contour with defined ratio\n",
    "        if h/plate_image.shape[0]>=0.5: # Select contour which has the height larger than 50% of the plate\n",
    "            # Draw bounding box arroung digit number\n",
    "            cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255,0), 2)\n",
    "\n",
    "            # Sperate number and gibe prediction\n",
    "            curr_num = thre_mor[y:y+h,x:x+w]\n",
    "            curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
    "            _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            crop_characters.append(curr_num)\n",
    "\n",
    "print(\"Detect {} letters...\".format(len(crop_characters)))\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.axis(False)\n",
    "plt.imshow(test_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\n",
    "\n",
    "for i in range(len(crop_characters)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.imshow(crop_characters[i],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_model(image,model,labels):\n",
    "    image = cv2.resize(image,(80,80))\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,3))\n",
    "cols = len(crop_characters)\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\n",
    "\n",
    "final_string = ''\n",
    "for i,character in enumerate(crop_characters):\n",
    "    fig.add_subplot(grid[i])\n",
    "    title = np.array2string(predict_from_model(character,model,labels))\n",
    "    plt.title('{}'.format(title.strip(\"'[]\"),fontsize=20))\n",
    "    final_string+=title.strip(\"'[]\")\n",
    "    plt.axis(False)\n",
    "    plt.imshow(character,cmap='gray')\n",
    "\n",
    "print(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
